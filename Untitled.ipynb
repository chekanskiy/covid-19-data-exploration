{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "import plotly\n",
    "import os\n",
    "from plotly import graph_objects as go\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "from scripts.charts import plot_line, plot_bar, plot_peak, print_charts_country\n",
    "from scripts.features import add_variables_covid, add_variables_apple, join_series_day_since, join_series_date\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jhu_processed = pd.read_csv(\"data-processed/data_jhu_world.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'land', 'lat', 'lng', 'iso_code', 'date', 'confirmed',\n",
       "       'confirmed_avg3', 'confirmed_change', 'confirmed_change_avg3',\n",
       "       'confirmed_change_3w', 'confirmed_change_pct',\n",
       "       'confirmed_change_pct_avg3', 'confirmed_change_pct_3w',\n",
       "       'confirmed_doubling_days', 'confirmed_doubling_days_3w',\n",
       "       'confirmed_doubling_days_avg3', 'confirmed_doubling_days_3w_avg3',\n",
       "       'confirmed_active_cases', 'confirmed_peak', 'confirmed_day_since_10',\n",
       "       'confirmed_per_100k', 'confirmed_change_per_100k', 'dead', 'dead_avg3',\n",
       "       'dead_change', 'dead_change_avg3', 'dead_change_3w', 'dead_change_pct',\n",
       "       'dead_change_pct_avg3', 'dead_change_pct_3w', 'dead_doubling_days',\n",
       "       'dead_doubling_days_3w', 'dead_doubling_days_avg3',\n",
       "       'dead_doubling_days_3w_avg3', 'dead_day_since_10', 'dead_per_100k',\n",
       "       'dead_change_per_100k', 'region_wb', 'population_wb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jhu_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>land</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>confirmed_avg3</th>\n",
       "      <th>confirmed_change</th>\n",
       "      <th>confirmed_change_avg3</th>\n",
       "      <th>...</th>\n",
       "      <th>dead_change_pct_3w</th>\n",
       "      <th>dead_doubling_days</th>\n",
       "      <th>dead_doubling_days_3w</th>\n",
       "      <th>dead_doubling_days_avg3</th>\n",
       "      <th>dead_doubling_days_3w_avg3</th>\n",
       "      <th>dead_day_since_10</th>\n",
       "      <th>dead_per_100k</th>\n",
       "      <th>dead_change_per_100k</th>\n",
       "      <th>region_wb</th>\n",
       "      <th>population_wb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>AFG</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>37172386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>37172386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>37172386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>37172386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>37172386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14458</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>57</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>14439018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14459</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>58</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>14439018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14460</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>59</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>14439018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14461</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>60</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>14439018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14462</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>61</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>14439018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14463 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       state         land   lat   lng iso_code  date  confirmed  \\\n",
       "0        NaN  Afghanistan  33.0  65.0      AFG     0        1.0   \n",
       "1        NaN  Afghanistan  33.0  65.0      AFG     1        1.0   \n",
       "2        NaN  Afghanistan  33.0  65.0      AFG     2        1.0   \n",
       "3        NaN  Afghanistan  33.0  65.0      AFG     3        1.0   \n",
       "4        NaN  Afghanistan  33.0  65.0      AFG     4        1.0   \n",
       "...      ...          ...   ...   ...      ...   ...        ...   \n",
       "14458    NaN     Zimbabwe -20.0  30.0      ZWE    57       42.0   \n",
       "14459    NaN     Zimbabwe -20.0  30.0      ZWE    58       44.0   \n",
       "14460    NaN     Zimbabwe -20.0  30.0      ZWE    59       46.0   \n",
       "14461    NaN     Zimbabwe -20.0  30.0      ZWE    60       46.0   \n",
       "14462    NaN     Zimbabwe -20.0  30.0      ZWE    61       48.0   \n",
       "\n",
       "       confirmed_avg3  confirmed_change  confirmed_change_avg3  ...  \\\n",
       "0                 NaN               NaN                    NaN  ...   \n",
       "1                 NaN               0.0                    NaN  ...   \n",
       "2                 1.0               0.0                    NaN  ...   \n",
       "3                 1.0               0.0                    0.0  ...   \n",
       "4                 1.0               0.0                    0.0  ...   \n",
       "...               ...               ...                    ...  ...   \n",
       "14458            41.0               0.0                    2.0  ...   \n",
       "14459            42.0               2.0                    2.0  ...   \n",
       "14460            44.0               2.0                    2.0  ...   \n",
       "14461            46.0               0.0                    2.0  ...   \n",
       "14462            46.0               2.0                    1.0  ...   \n",
       "\n",
       "       dead_change_pct_3w  dead_doubling_days  dead_doubling_days_3w  \\\n",
       "0                     NaN                 0.0                    0.0   \n",
       "1                     NaN                 0.0                    0.0   \n",
       "2                     NaN                 0.0                    0.0   \n",
       "3                     NaN                 0.0                    0.0   \n",
       "4                     NaN                 0.0                    0.0   \n",
       "...                   ...                 ...                    ...   \n",
       "14458                 NaN               100.0                    0.0   \n",
       "14459                 NaN               100.0                    0.0   \n",
       "14460                 NaN               100.0                    0.0   \n",
       "14461                 NaN               100.0                    0.0   \n",
       "14462                 NaN               100.0                    0.0   \n",
       "\n",
       "       dead_doubling_days_avg3  dead_doubling_days_3w_avg3  dead_day_since_10  \\\n",
       "0                          NaN                         NaN                  0   \n",
       "1                          NaN                         NaN                  0   \n",
       "2                          0.0                         0.0                  0   \n",
       "3                          0.0                         0.0                  0   \n",
       "4                          0.0                         0.0                  0   \n",
       "...                        ...                         ...                ...   \n",
       "14458                    100.0                         0.0                  0   \n",
       "14459                    100.0                         0.0                  0   \n",
       "14460                    100.0                         0.0                  0   \n",
       "14461                    100.0                         0.0                  0   \n",
       "14462                    100.0                         0.0                  0   \n",
       "\n",
       "       dead_per_100k  dead_change_per_100k            region_wb  population_wb  \n",
       "0                NaN                   NaN           South Asia     37172386.0  \n",
       "1                NaN                   NaN           South Asia     37172386.0  \n",
       "2                NaN                   NaN           South Asia     37172386.0  \n",
       "3                NaN                   NaN           South Asia     37172386.0  \n",
       "4                NaN                   NaN           South Asia     37172386.0  \n",
       "...              ...                   ...                  ...            ...  \n",
       "14458       0.027703                   0.0  Sub-Saharan Africa      14439018.0  \n",
       "14459       0.027703                   0.0  Sub-Saharan Africa      14439018.0  \n",
       "14460       0.027703                   0.0  Sub-Saharan Africa      14439018.0  \n",
       "14461       0.027703                   0.0  Sub-Saharan Africa      14439018.0  \n",
       "14462       0.027703                   0.0  Sub-Saharan Africa      14439018.0  \n",
       "\n",
       "[14463 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jhu_processed = pd.read_csv(\"data-processed/data_jhu_world.csv\")\n",
    "df_jhu_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading applemobilitytrends-2020-05-19.csv report\n",
      "Missing population data for 6 countries\n",
      "\n",
      "['Taiwan*' 'Eritrea' 'Diamond Princess' 'MS Zaandam' 'Holy See'\n",
      " 'Western Sahara'] \n",
      "\n",
      "Missing COVID data for 4 countries\n",
      "\n",
      "['Diamond Princess' 'MS Zaandam' 'Holy See' 'Western Sahara'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import warnings\n",
    "import pathlib\n",
    "import os, sys\n",
    "import dotenv\n",
    "from scripts.features import add_variables_covid, add_variables_apple\n",
    "from scripts.utils import DASH_COLUMNS\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "JHU_INPUT = os.environ.get(\"JHU_INPUT\")\n",
    "INPUT = os.environ.get(\"INPUT\")\n",
    "PROCESSED = os.environ.get(\"PROCESSED\")\n",
    "DASH_PROCESSED = os.environ.get(\"DASH_PROCESSED\")\n",
    "\n",
    "APP_PATH = \"/Users/chekanskiy/Documents/projects/covid-19-exploration\"\n",
    "sys.path.insert(0, APP_PATH)\n",
    "\n",
    "path_jhu_data = f'{APP_PATH}{INPUT}'\n",
    "path_input = f'{APP_PATH}{INPUT}'\n",
    "path_processed = f'{APP_PATH}{PROCESSED}'\n",
    "path_processed_dash = f'{APP_PATH}{DASH_PROCESSED}'\n",
    "latest_apple_report = sorted(os.listdir(f'{APP_PATH}{INPUT}apple-mobility'), reverse=True)[0]\n",
    "print(f'Loading {latest_apple_report} report')\n",
    "\n",
    "\n",
    "def melt_apple_df(dfapple):\n",
    "    apple_melted = dfapple.melt(id_vars=[c for c in dfapple.columns if '2020-' not in c], value_vars=[c for c in dfapple.columns if '2020-' in c])\n",
    "    apple_melted.rename({'variable': 'date'}, axis=1, inplace=True)\n",
    "    apple_melted.loc[:, [c for c in apple_melted.columns if c != 'value']] = apple_melted.loc[:, [c for c in apple_melted.columns if c != 'value']].fillna('n/a')\n",
    "    apple_melted_pivoted = apple_melted.pivot_table(index=[c for c in apple_melted.columns if c not in ['value', 'transportation_type']],columns='transportation_type', values='value')\n",
    "    apple_melted_pivoted = apple_melted_pivoted.reset_index()\n",
    "    apple_melted_pivoted['date'] = apple_melted_pivoted['date'].astype('datetime64[ns]')\n",
    "    apple_melted_pivoted = apple_melted_pivoted.set_index('date', drop=False).rename_axis('date_index', axis=0)\n",
    "    return apple_melted_pivoted\n",
    "\n",
    "\n",
    "def fix_countries(df):\n",
    "    df.loc[df.state.str.contains('Hong Kong') == True, 'iso_code'] = 'HKG'\n",
    "    df.loc[df.state.str.contains('Macau') == True, 'iso_code'] = 'MAC'\n",
    "    df.loc[df.state.str.contains('Hong Kong') == True, 'state'] = np.NaN\n",
    "    df.loc[df.state.str.contains('Macau') == True, 'state'] = np.NaN\n",
    "    df.loc[df.iso_code.str.contains('HKG') == True, 'country'] = 'Hong Kong'\n",
    "    df.loc[df.iso_code.str.contains('MAC') == True, 'country'] = 'Macau'\n",
    "\n",
    "    s = df.loc[df.iso_code == 'CHN', [c for c in df.columns if '/20' in c]].sum()\n",
    "    s['country'] = 'China'\n",
    "    s['iso_code'] = 'CHN'\n",
    "    df = pd.concat([df, s.to_frame().T, ], axis=0)\n",
    "\n",
    "    s = df.loc[df.country.str.contains('Canada') == True, [c for c in df.columns if '/20' in c]].sum()\n",
    "    s['country'] = 'Canada'\n",
    "    s['iso_code'] = 'CAN'\n",
    "    df = pd.concat([df, s.to_frame().T, ], axis=0)\n",
    "\n",
    "    s = df.loc[df.country.str.contains('Australia') == True, [c for c in df.columns if '/20' in c]].sum()\n",
    "    s['country'] = 'Australia'\n",
    "    s['iso_code'] = 'AUS'\n",
    "    df = pd.concat([df, s.to_frame().T, ], axis=0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "subset_columns = False\n",
    "\n",
    "# Load WB Population Data\n",
    "df_population = pd.read_csv(f\"{path_processed}wb/population.csv\")\n",
    "\n",
    "# Pull the latest Data\n",
    "os.chdir(f'{APP_PATH}{JHU_INPUT}')\n",
    "# os.system(\"git pull\")\n",
    "os.chdir(f'{APP_PATH}')\n",
    "\n",
    "# Load JHU Data\n",
    "df_covid_conf = pd.read_csv(\n",
    "    f\"{APP_PATH}{JHU_INPUT}/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\")\n",
    "df_covid_dead = pd.read_csv(\n",
    "    f\"{APP_PATH}{JHU_INPUT}/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\")\n",
    "df_uid = pd.read_csv(f\"{APP_PATH}{JHU_INPUT}/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv\")\n",
    "\n",
    "df_uid = df_uid.loc[df_uid['Province_State'].isnull() == True, ['iso3', 'Country_Region']]\n",
    "df_uid.columns = ['iso_code', 'country']\n",
    "\n",
    "df_covid_conf.columns = ['state', 'country', 'lat', 'lng'] + list(df_covid_conf.columns[4:])\n",
    "df_covid_dead.columns = ['state', 'country', 'lat', 'lng'] + list(df_covid_dead.columns[4:])\n",
    "df_covid_conf = df_covid_conf.merge(df_uid, how='outer', on='country', suffixes=('_x', '_y'))\n",
    "df_covid_dead = df_covid_dead.merge(df_uid, how='outer', on='country', suffixes=('_x', '_y'))\n",
    "\n",
    "# Fix Country Names and Aggregate Countries by province\n",
    "df_covid_conf = fix_countries(df_covid_conf)\n",
    "df_covid_dead = fix_countries(df_covid_dead)\n",
    "\n",
    "# Take only aggregated countries\n",
    "df_covid_conf = df_covid_conf.loc[df_covid_conf['state'].isnull() == True, :]\n",
    "df_covid_dead = df_covid_dead.loc[df_covid_dead['state'].isnull() == True, :]\n",
    "\n",
    "# Join WB population\n",
    "df_population_joined = df_population.merge(df_covid_conf.loc[:, ['iso_code', 'country']].drop_duplicates(),\n",
    "                                           how='outer', on='iso_code', suffixes=('_x', '_y'), left_index=False,\n",
    "                                           right_index=False, )\n",
    "\n",
    "missing_popuation = df_population_joined.loc[df_population_joined.population.isnull() == True].sort_values(by='region')\n",
    "print(f\"Missing population data for {len(missing_popuation)} countries\\n\")\n",
    "print(missing_popuation.country.unique(), '\\n')\n",
    "\n",
    "missing_covid_data = df_population_joined.loc[df_population_joined.country_wb.isnull() == True].sort_values(\n",
    "    by='region')\n",
    "print(f\"Missing COVID data for {len(missing_covid_data)} countries\\n\")\n",
    "print(missing_covid_data.country.unique(), '\\n')\n",
    "\n",
    "\n",
    "def melt_jhu_data(df, value_column):\n",
    "    df = df.melt(id_vars=[c for c in df.columns if '/20' not in c],\n",
    "                 value_vars=[c for c in df.columns if '/20' in c])\n",
    "    df = df.rename({'variable': 'date', 'value': value_column}, axis=1)\n",
    "    df['date'] = df['date'].astype('datetime64[ns]')\n",
    "    if value_column != 'confirmed':\n",
    "        # df = df.loc[['iso_code', 'lat', 'lng'], :]\n",
    "        df.drop(['lat', 'lng', 'iso_code'], axis=1, inplace=True)\n",
    "    df = df.sort_values(by=['country', 'state', 'date'], ascending=True)\n",
    "    df = df.set_index('date', drop=False).rename_axis('date_index')\n",
    "    # df[value_column] = df[value_column].astype(float)\n",
    "    return df\n",
    "\n",
    "df_covid_conf_t = melt_jhu_data(df_covid_conf, 'confirmed')\n",
    "df_covid_dead_t = melt_jhu_data(df_covid_dead, 'dead')\n",
    "\n",
    "def prepare_df_country(df_confirmed, df_dead, df_population, country, date_cutoff=None):\n",
    "    if date_cutoff is not None:\n",
    "        df_confirmed = df_confirmed.loc[(df_confirmed.index >= date_cutoff) &\n",
    "                                        (df_confirmed.country == country) &\n",
    "                                        (df_confirmed['confirmed'] > 0), :]\n",
    "        df_dead = df_dead.loc[(df_dead.index >= date_cutoff) &\n",
    "                              (df_dead.country == country) &\n",
    "                                        (df_dead['dead'] > 0), :]\n",
    "    else:\n",
    "        df_confirmed = df_confirmed.loc[(df_confirmed.country == country) &\n",
    "                                        (df_confirmed['confirmed'] > 0), :]\n",
    "        df_dead = df_dead.loc[(df_dead.country == country) &\n",
    "                                        (df_dead['dead'] > 0), :]\n",
    "\n",
    "    try:\n",
    "        pop = df_population.loc[df_population.country == country, 'population'].values[0]\n",
    "        iso_code = df_population.loc[df_population.country == country, 'iso_code'].values[0]\n",
    "        region = df_population.loc[df_population.country == country, 'region'].values[0]\n",
    "    except:\n",
    "        print('No population data for :', country)\n",
    "        return None\n",
    "\n",
    "    df_confirmed = add_variables_covid(df_confirmed, population=pop)\n",
    "\n",
    "    df = df_confirmed.merge(df_dead, how='outer', on=['country', 'state', 'date'])\n",
    "\n",
    "    df = add_variables_covid(df, column='dead', population=pop)\n",
    "\n",
    "    # df['land'] = country\n",
    "    df['iso_code'] = iso_code\n",
    "    df['region_wb'] = region\n",
    "    df['population_wb'] = pop\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state         land   lat   lng iso_code       date confirmed  \\\n",
      "0   NaN  Afghanistan  33.0  65.0      AFG 2020-02-24         1   \n",
      "1   NaN  Afghanistan  33.0  65.0      AFG 2020-02-25         1   \n",
      "2   NaN  Afghanistan  33.0  65.0      AFG 2020-02-26         1   \n",
      "3   NaN  Afghanistan  33.0  65.0      AFG 2020-02-27         1   \n",
      "4   NaN  Afghanistan  33.0  65.0      AFG 2020-02-28         1   \n",
      "\n",
      "   confirmed_avg3 confirmed_change  confirmed_change_avg3  \\\n",
      "0             NaN              NaN                    NaN   \n",
      "1             NaN                0                    NaN   \n",
      "2             1.0                0                    NaN   \n",
      "3             1.0                0                    0.0   \n",
      "4             1.0                0                    0.0   \n",
      "\n",
      "   confirmed_change_3w confirmed_change_pct  confirmed_change_pct_avg3  \\\n",
      "0                  NaN                  NaN                        NaN   \n",
      "1                  NaN                    0                        NaN   \n",
      "2                  NaN                    0                        NaN   \n",
      "3                  NaN                    0                        0.0   \n",
      "4                  NaN                    0                        0.0   \n",
      "\n",
      "  confirmed_change_pct_3w  confirmed_doubling_days  \\\n",
      "0                     NaN                      0.0   \n",
      "1                     NaN                    100.0   \n",
      "2                     NaN                    100.0   \n",
      "3                     NaN                    100.0   \n",
      "4                     NaN                    100.0   \n",
      "\n",
      "   confirmed_doubling_days_3w  confirmed_doubling_days_avg3  \\\n",
      "0                         0.0                           NaN   \n",
      "1                         0.0                           NaN   \n",
      "2                         0.0                          75.0   \n",
      "3                         0.0                         100.0   \n",
      "4                         0.0                         100.0   \n",
      "\n",
      "   confirmed_doubling_days_3w_avg3  confirmed_active_cases  confirmed_peak  \\\n",
      "0                              NaN                     NaN             NaN   \n",
      "1                              NaN                     NaN             NaN   \n",
      "2                              0.0                     NaN             NaN   \n",
      "3                              0.0                     NaN             NaN   \n",
      "4                              0.0                     NaN             NaN   \n",
      "\n",
      "   confirmed_day_since_10 confirmed_per_100k confirmed_change_per_100k dead  \\\n",
      "0                       0         0.00269017                       NaN  NaN   \n",
      "1                       0         0.00269017                         0  NaN   \n",
      "2                       0         0.00269017                         0  NaN   \n",
      "3                       0         0.00269017                         0  NaN   \n",
      "4                       0         0.00269017                         0  NaN   \n",
      "\n",
      "   dead_avg3 dead_change  dead_change_avg3  dead_change_3w dead_change_pct  \\\n",
      "0        NaN         NaN               NaN             NaN             NaN   \n",
      "1        NaN         NaN               NaN             NaN             NaN   \n",
      "2        NaN         NaN               NaN             NaN             NaN   \n",
      "3        NaN         NaN               NaN             NaN             NaN   \n",
      "4        NaN         NaN               NaN             NaN             NaN   \n",
      "\n",
      "   dead_change_pct_avg3 dead_change_pct_3w  dead_doubling_days  \\\n",
      "0                   NaN                NaN                 0.0   \n",
      "1                   NaN                NaN                 0.0   \n",
      "2                   NaN                NaN                 0.0   \n",
      "3                   NaN                NaN                 0.0   \n",
      "4                   NaN                NaN                 0.0   \n",
      "\n",
      "   dead_doubling_days_3w  dead_doubling_days_avg3  dead_doubling_days_3w_avg3  \\\n",
      "0                    0.0                      NaN                         NaN   \n",
      "1                    0.0                      NaN                         NaN   \n",
      "2                    0.0                      0.0                         0.0   \n",
      "3                    0.0                      0.0                         0.0   \n",
      "4                    0.0                      0.0                         0.0   \n",
      "\n",
      "   dead_day_since_10 dead_per_100k dead_change_per_100k   region_wb  \\\n",
      "0                  0           NaN                  NaN  South Asia   \n",
      "1                  0           NaN                  NaN  South Asia   \n",
      "2                  0           NaN                  NaN  South Asia   \n",
      "3                  0           NaN                  NaN  South Asia   \n",
      "4                  0           NaN                  NaN  South Asia   \n",
      "\n",
      "   population_wb  \n",
      "0     37172386.0  \n",
      "1     37172386.0  \n",
      "2     37172386.0  \n",
      "3     37172386.0  \n",
      "4     37172386.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def country_iterate_jhu(df_confirmed, df_dead):\n",
    "    _list = list()\n",
    "    for country in df_confirmed.country.unique():\n",
    "        df = prepare_df_country(df_confirmed, df_dead, df_population_joined, country)\n",
    "        if df is not None:\n",
    "            _list.append(df)\n",
    "    return pd.concat([df for df in _list])\n",
    "\n",
    "\n",
    "df_jhu_processed = country_iterate_jhu(df_covid_conf_t, df_covid_dead_t)\n",
    "df_jhu_processed.rename({'country': 'land'}, axis=1, inplace=True)\n",
    "print(df_jhu_processed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_jhu_processed = df_jhu_processed.loc[df_jhu_processed.region_wb.isnull() == False]\n",
    "df_eu_countries = pd.read_csv(f'{path_input}eu_countries.csv')\n",
    "df_jhu_processed.loc[df_jhu_processed.land.isin(df_eu_countries.Country) == True, 'region_wb'] = 'European Union'\n",
    "\n",
    "df_jhu_processed.to_csv(f'{path_processed}data_jhu_world.csv', index=False)\n",
    "if subset_columns:\n",
    "    df_jhu_processed.loc[:, DASH_COLUMNS].to_csv(f'{path_processed_dash}data_jhu_world.csv', index=False)\n",
    "else:\n",
    "    df_jhu_processed.to_csv(f'{path_processed_dash}data_jhu_world.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                               object\n",
       "land                                object\n",
       "lat                                float64\n",
       "lng                                float64\n",
       "iso_code                            object\n",
       "date                                 int64\n",
       "confirmed                           object\n",
       "confirmed_avg3                     float64\n",
       "confirmed_change                    object\n",
       "confirmed_change_avg3              float64\n",
       "confirmed_change_3w                float64\n",
       "confirmed_change_pct                object\n",
       "confirmed_change_pct_avg3          float64\n",
       "confirmed_change_pct_3w             object\n",
       "confirmed_doubling_days            float64\n",
       "confirmed_doubling_days_3w         float64\n",
       "confirmed_doubling_days_avg3       float64\n",
       "confirmed_doubling_days_3w_avg3    float64\n",
       "confirmed_active_cases             float64\n",
       "confirmed_peak                     float64\n",
       "confirmed_day_since_10               int64\n",
       "confirmed_per_100k                  object\n",
       "confirmed_change_per_100k           object\n",
       "dead                                object\n",
       "dead_avg3                          float64\n",
       "dead_change                         object\n",
       "dead_change_avg3                   float64\n",
       "dead_change_3w                     float64\n",
       "dead_change_pct                     object\n",
       "dead_change_pct_avg3               float64\n",
       "dead_change_pct_3w                  object\n",
       "dead_doubling_days                 float64\n",
       "dead_doubling_days_3w              float64\n",
       "dead_doubling_days_avg3            float64\n",
       "dead_doubling_days_3w_avg3         float64\n",
       "dead_day_since_10                    int64\n",
       "dead_per_100k                       object\n",
       "dead_change_per_100k                object\n",
       "region_wb                           object\n",
       "population_wb                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jhu_processed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
